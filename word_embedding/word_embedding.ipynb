{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231ff203",
   "metadata": {},
   "source": [
    "# Embed captions with word2vec\n",
    "\n",
    "## Load and preprocess captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7822fd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "dir_root = Path().resolve().parent\n",
    "import sys; sys.path.append(str(dir_root))\n",
    "from settings import Dir, Params\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "618af0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_useless(words):\n",
    "    return [w for w in words if w not in ['http','https','photo','picture','image','insta','instagram','instagood','post']]\n",
    "\n",
    "def preprocess(w): # remove stop words, hashtags, non-ASCII and lower characters from w\n",
    "    return remove_stopwords(re.sub(\"[^a-zA-Z ]\", '', w.replace('#', ' ')).lower())\n",
    "\n",
    "class Captions:  # iterator for captions\n",
    "    def __iter__(self):\n",
    "        for f in itertools.islice(Dir.captions.rglob(\"*.txt\"), 10000):\n",
    "            yield remove_useless(preprocess(f.read_text()).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b6096c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['george', 'nelson', 'herman', 'miller', 'platform', 'bench', 'perfecto']\n",
      "['currently', 'bpi', 'sports', 'niagenix', 'bam', 'amino', 'strong', 'whats', 'wallet', 'lol', 'mean', 'stack', 'weeks', 'outish', 'teamventura', 'ifbb', 'ifbbpro', 'npc', 'bpi', 'bpisports', 'training', 'chicago', 'lafitness', 'xsport', 'muscle', 'aesthetics']\n"
     ]
    }
   ],
   "source": [
    "for c in itertools.islice(Captions(), 2):\n",
    "    print(c)  # show some captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c284f0",
   "metadata": {},
   "source": [
    "## Train a word2vec modelitertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb744eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=Captions(),\n",
    "                 vector_size=Params.dim_embedding,\n",
    "                 min_count=10,\n",
    "                 workers=Params.workers\n",
    "                )\n",
    "model.save(\"model_captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54986603",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"model_captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81aaf2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of captions: 10000\n",
      "Number of words: 3122\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of captions: {model.corpus_count}\")\n",
    "print(f\"Number of words: {len(model.wv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc52c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"caption\": model.wv.index_to_key, \n",
    "              \"count\": map(lambda w: model.wv.get_vecattr(w, \"count\"), model.wv.index_to_key)\n",
    "             }) \\\n",
    "  .set_index(\"caption\") \\\n",
    "  .iloc[:20].T  # 20 most frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb97d51",
   "metadata": {},
   "source": [
    "## Explore results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8096f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(\"fashion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['food'] , negative=['healthy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similar_by_vector(model.wv.get_vector('actress') + model.wv.get_vector('woman'), topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd92981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.graph_objs as go\n",
    "    \n",
    "def reduce_2d(model):\n",
    "    vectors = TSNE(n_components=2).fit_transform(np.asarray(model.wv.vectors[10:50]))\n",
    "    return [v[0] for v in vectors], [v[1] for v in vectors], np.asarray(model.wv.index_to_key[10:50])\n",
    "\n",
    "x_vals, y_vals, labels = reduce_2d(model)\n",
    "init_notebook_mode(connected=True)\n",
    "iplot([go.Scatter(x=x_vals, y=y_vals, mode='text', text=labels)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1027d1be",
   "metadata": {},
   "source": [
    "## Save vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71ae7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representation(wv, caption):  # return the vector representation of caption\n",
    "    for w in caption.split():\n",
    "        if len(w) > 0 and w[0] == '#':\n",
    "            if w[1:] in wv.key_to_index:\n",
    "                return wv.get_vector(w[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede86cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.rm_dir(Dir.caption_vectors)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def save_embedding(dir):\n",
    "    for n, file_caption in itertools.islice(enumerate(dir.iterdir()), Params.samples): \n",
    "        v = representation(model.wv, file_caption.read_text())\n",
    "        if v is not None:\n",
    "            mode = \"train\"\n",
    "            if n > .7*Params.samples:\n",
    "                mode = \"validate\"\n",
    "            if n >= .9*Params.samples:\n",
    "                mode = \"test\"\n",
    "            file = Dir.caption_vectors / f\"{mode}/{dir.name}/{file_caption.name}\"\n",
    "            Path(file.parent).mkdir(parents=True, exist_ok=True)\n",
    "            np.savetxt(str(file), v)\n",
    "\n",
    "with Pool(Params.workers) as p:\n",
    "    p.map(save_embedding, Dir.captions.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a868ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md,ipynb",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown"
   }
  },
  "kernelspec": {
   "display_name": "image-retrieval",
   "language": "python",
   "name": "image-retrieval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
