{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitd3062a9d535948728b3cdbf50ee7ab6e",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Load and preprocess data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set([\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def rm_stop(words):  # remove stop words from list of words\n",
    "    return [w for w_ in w.split() if w_ not in stop_words]\n",
    "\n",
    "def preprocess(w):  # remove non-ASCII and lower characters from w\n",
    "    return rm_stop(re.sub(\"[^a-zA-Z ]\", '', w).lower())\n",
    "\n",
    "class InstaCities:\n",
    "    def __iter__(self):\n",
    "        for f in Path(\"../InstaCities1M/captions_resized_1M/cities_instagram\").glob(\"**/*.txt\"):\n",
    "            yield preprocess(f.read_text())"
   ]
  },
  {
   "source": [
    "# Word2Vec model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = InstaCities()\n",
    "model = gensim.models.Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
    "model.save(\"model_insta_cities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('town', 0.637067973613739),\n",
       " ('buildings', 0.6352139115333557),\n",
       " ('streets', 0.6173369288444519),\n",
       " ('place', 0.6166399717330933),\n",
       " ('cities', 0.6086874008178711),\n",
       " ('building', 0.5980123281478882),\n",
       " ('world', 0.5960747003555298),\n",
       " ('citys', 0.5865464806556702),\n",
       " ('skyline', 0.581667423248291),\n",
       " ('downtown', 0.5648966431617737)]"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "wv = model.wv\n",
    "wv.most_similar('city', topn=10)"
   ]
  },
  {
   "source": [
    "# Comparison with Google News model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv_news = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('DeVillers_reports', 0.5512474179267883),\n ('limited_edition_MGTF', 0.5153472423553467),\n ('e_mail_mikenadel@sbcglobal.net', 0.5088345408439636),\n ('TAKE_TWO_An', 0.4983653426170349),\n ('KTEN_Deeda_Payton', 0.48801666498184204)]\n[('cool', 0.5977016091346741),\n ('sport', 0.5970734357833862),\n ('cars', 0.5735954642295837),\n ('fitness', 0.5330854058265686),\n ('fun', 0.5290842056274414)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(wv_news.most_similar(positive=[\"car\", \"sports\", \"hairstyle\", \"food\", \"toronto\"], topn=5))\n",
    "pprint(model.wv.most_similar(positive=[\"car\", \"sports\", \"hairstyle\", \"food\", \"toronto\"], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most similar words to toronto + wild:\n",
      "InstaCities: ['toronto', 'ontario', 'tdot', 'torontolife', 'theix', 'wild', 'yyz']\n",
      "Google News: ['toronto', 'wild', 'montreal', 'vancouver', 'blackpool', 'alberta', 'okc']\n",
      "\n",
      "Most similar words to happy + family:\n",
      "InstaCities: ['happy', 'family', 'friendship', 'sister', 'mum', 'sisters', 'friends']\n",
      "Google News: ['happy', 'family', 'glad', 'thankful', 'Said_Hirschbeck', 'friends', 'safe_Arlene_Deche']\n",
      "\n",
      "Most similar words to food + healthy:\n",
      "InstaCities: ['food', 'healthy', 'foods', 'diet', 'eat', 'nutrition', 'tasty']\n",
      "Google News: ['healthy', 'food', 'nutritious', 'healthier_tastier', 'nutritionally_sound', 'foods', 'nutritiously']\n",
      "\n",
      "Most similar words to food + sweet:\n",
      "InstaCities: ['food', 'sweet', 'tasty', 'delicious', 'yummy', 'foods', 'taste']\n",
      "Google News: ['sweet', 'food', 'delicious', 'yummy', 'crunchy_salty', 'savory_delights', 'tasty']\n",
      "\n",
      "Most similar words to food - healthy:\n",
      "InstaCities: ['food', 'cookingwithfire', 'weddingportraiture', 'chachacha', 'venues', 'annvitatearoom', 'courtneymacfarlane']\n",
      "Google News: ['food', 'Food', 'food_stuffs', 'foodstuffs', 'foodstuff', 'staple_foods', 'goods']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "top = 7\n",
    "\n",
    "def similar(wv, *words):\n",
    "    v = np.sum([wv.get_vector(w) for w in words], axis=0)\n",
    "    return [w[0] for w in wv.similar_by_vector(v, topn=top)]\n",
    "\n",
    "for w1, w2 in [(\"toronto\", \"wild\"), (\"happy\", \"family\"), (\"food\", \"healthy\"), (\"food\", \"sweet\")]:\n",
    "    print(f\"Most similar words to {w1} + {w2}:\")\n",
    "    print(f\"InstaCities: {similar(wv, w1, w2)}\")\n",
    "    print(f\"Google News: {similar(wv_news, w1, w2)}\\n\")\n",
    "\n",
    "print(f\"Most similar words to food - healthy:\")\n",
    "print(f\"InstaCities: {[w[0] for w in wv.similar_by_vector(wv.get_vector('food') - wv.get_vector('healthy'), topn=top)]}\")\n",
    "print(f\"Google News: {[w[0] for w in wv_news.similar_by_vector(wv_news.get_vector('food') - wv_news.get_vector('healthy'), topn=top)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dog\ndog\n"
     ]
    }
   ],
   "source": [
    "print(wv.doesnt_match([\"man\", \"woman\", \"kid\", \"dog\"]))\n",
    "print(wv_news.doesnt_match([\"man\", \"woman\", \"kid\", \"dog\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.70655835\n0.76640123\n"
     ]
    }
   ],
   "source": [
    "print(wv.similarity('woman', 'man'))\n",
    "print(wv_news.similarity('woman', 'man'))"
   ]
  },
  {
   "source": [
    "# Caption representation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def split_train_validation_test():\n",
    "    train, validation, test = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "    for dir_city in Path(\"../InstaCities1M/captions_resized_1M/cities_instagram\").iterdir():\n",
    "        for file_img in dir_city.iterdir():\n",
    "            words = preprocess(file_img.read_text())\n",
    "            words = [wv.get_vector(w) for w in words if w in wv.key_to_index]\n",
    "            if len(words) > 0:\n",
    "                v = np.sum(words, axis=0)\n",
    "                v -= min(v)\n",
    "                if max(v) != 0:\n",
    "                    v /= max(v)\n",
    "                S = train[dir_city.name]\n",
    "                if len(S) > 80_000:\n",
    "                    S = validation[dir_city.name]\n",
    "                if len(S) > 85_000:\n",
    "                    S = test[dir_city.name]\n",
    "                S.append((file_img.name, v))\n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-c6391cf21bcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_validation_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-111-4c7fc16c3306>\u001b[0m in \u001b[0;36msplit_train_validation_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdir_city\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "train, validation, test = split_train_validation_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "wv.key_to_index['tree']"
   ]
  }
 ]
}