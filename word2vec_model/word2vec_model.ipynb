{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitd3062a9d535948728b3cdbf50ee7ab6e",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Load and preprocess data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set([\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def rm_stop(words):  # remove stop words from list of words\n",
    "    return [w for w_ in w.split() if w_ not in stop_words]\n",
    "\n",
    "def preprocess(w):  # remove non-ASCII and lower characters from w\n",
    "    return rm_stop(re.sub(\"[^a-zA-Z ]\", '', w).lower())\n",
    "\n",
    "class InstaCities:\n",
    "    def __iter__(self):\n",
    "        for f in Path(\"../InstaCities1M\").glob(\"**/*.txt\"):\n",
    "            yield preprocess(f.read_text())"
   ]
  },
  {
   "source": [
    "# Word2Vec model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = InstaCities()\n",
    "model = gensim.models.Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
    "model.save(\"model_insta_cities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('town', 0.637067973613739),\n",
       " ('buildings', 0.6352139115333557),\n",
       " ('streets', 0.6173369288444519),\n",
       " ('place', 0.6166399717330933),\n",
       " ('cities', 0.6086874008178711),\n",
       " ('building', 0.5980123281478882),\n",
       " ('world', 0.5960747003555298),\n",
       " ('citys', 0.5865464806556702),\n",
       " ('skyline', 0.581667423248291),\n",
       " ('downtown', 0.5648966431617737)]"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "wv = model.wv\n",
    "wv.most_similar('city', topn=10)"
   ]
  },
  {
   "source": [
    "# Comparison with Google News model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv_news = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('DeVillers_reports', 0.5512474179267883),\n ('limited_edition_MGTF', 0.5153472423553467),\n ('e_mail_mikenadel@sbcglobal.net', 0.5088345408439636),\n ('TAKE_TWO_An', 0.4983653426170349),\n ('KTEN_Deeda_Payton', 0.48801666498184204)]\n[('cool', 0.5977016091346741),\n ('sport', 0.5970734357833862),\n ('cars', 0.5735954642295837),\n ('fitness', 0.5330854058265686),\n ('fun', 0.5290842056274414)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(wv_news.most_similar(positive=[\"car\", \"sports\", \"hairstyle\", \"food\", \"toronto\"], topn=5))\n",
    "pprint(model.wv.most_similar(positive=[\"car\", \"sports\", \"hairstyle\", \"food\", \"toronto\"], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most similar words to toronto + wild:\n",
      "InstaCities: ['shiamak', 'prenup', 'mattyctattoo', 'estonian', 'goldnova', 'supportplease', 'illtattoogmailcom']\n",
      "Google News: ['Seashore_Trolley_Museum', 'Inc._OTCBB_AMOR', 'cyclic_steaming', 'CaFCP', 'ARBOC_Mobility', 'CNHA', 'SunLine_Transit']\n",
      "\n",
      "Most similar words to happy + family:\n",
      "InstaCities: ['todaydailykoreaselfieinstadailytravelinstatraveltravelgrammelbourneaustraliaweekend', 'tigres', 'grindseason', 'algorithms', 'perthlife', 'coworkingspaces', 'powai']\n",
      "Google News: ['SB####_ONX', 'boringly', 'Initiates_Independent_Research', 'PDGFR', 'giddily', 'Cbl', '##c###']\n",
      "\n",
      "Most similar words to food + healthy:\n",
      "InstaCities: ['fiestainfantil', 'monumentvalley', 'salinas', 'fremont', 'cuu', 'ghardaia', 'stockton']\n",
      "Google News: ['Rollingstone.com', 'Sveriges_Radio_SR', 'Lif', 'Onion_AV_Club', 'Merryday', 'MEGADETH_drummer', 'Laiho']\n",
      "\n",
      "Most similar words to food + sweet:\n",
      "InstaCities: ['diamondwholesaler', 'tudungcomel', 'nycla', 'dubaibasedmakeupartist', 'makeupservicekl', 'lucci', 'internationalshipping']\n",
      "Google News: ['TV_Funhouse_cartoons', 'felonies', 'Basem_Motorcycles_Blog', 'Moussa_Abu_Marzouk', 'Yonath', 'degree_felonies_punishable', 'Garlin']\n",
      "\n",
      "Most similar words to food - healthy:\n",
      "InstaCities: ['food', 'cookingwithfire', 'weddingportraiture', 'chachacha', 'venues', 'annvitatearoom', 'courtneymacfarlane']\n",
      "Google News: ['food', 'Food', 'food_stuffs', 'foodstuffs', 'foodstuff', 'staple_foods', 'goods']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "top = 7\n",
    "\n",
    "def similar(wv, *words):\n",
    "    v = np.sum(np.array(wv.get_vector(w) for w in words))\n",
    "    return [w[0] for w in wv.similar_by_vector(v, topn=top)]\n",
    "\n",
    "for w1, w2 in [(\"toronto\", \"wild\"), (\"happy\", \"family\"), (\"food\", \"healthy\"), (\"food\", \"sweet\")]:\n",
    "    print(f\"Most similar words to {w1} + {w2}:\")\n",
    "    print(f\"InstaCities: {similar(wv, w1, w2)}\")\n",
    "    print(f\"Google News: {similar(wv_news, w1, w2)}\\n\")\n",
    "\n",
    "print(f\"Most similar words to food - healthy:\")\n",
    "print(f\"InstaCities: {[w[0] for w in wv.similar_by_vector(wv.get_vector('food') - wv.get_vector('healthy'), topn=top)]}\")\n",
    "print(f\"Google News: {[w[0] for w in wv_news.similar_by_vector(wv_news.get_vector('food') - wv_news.get_vector('healthy'), topn=top)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dog\ndog\n"
     ]
    }
   ],
   "source": [
    "print(wv.doesnt_match([\"man\", \"woman\", \"kid\", \"dog\"]))\n",
    "print(wv_news.doesnt_match([\"man\", \"woman\", \"kid\", \"dog\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.70655835\n0.76640123\n"
     ]
    }
   ],
   "source": [
    "print(wv.similarity('woman', 'man'))\n",
    "print(wv_news.similarity('woman', 'man'))"
   ]
  }
 ]
}